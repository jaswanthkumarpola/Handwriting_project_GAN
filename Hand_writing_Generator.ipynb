{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb85c1e-5e8c-43c8-8674-687f43fb5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2daf3f-35bd-4907-85f5-3b9f4afc4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "image_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f494b4-5398-4a02-9d75-5b5d0cc02eee",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "# Create output folder \n",
    "os.makedirs(\"gan_images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ce5f3-5c98-48b0-9dd2-d2e1c7d09932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Dataset Loader (MNIST) \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([1], [1])\n",
    "])\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# from torchvision.datasets import FashionMNIST # Or MNIST, if you're using that\n",
    "# train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=transform) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703a538-ea5a-4b63-b24e-35b0fdd00606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, image_size * image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, image_size, image_size)\n",
    "        return img   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1343812-2239-4598-b7db-2e6306c313ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32 # new image size\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size, 512),  # was 784 before\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d6336-7892-41b3-b09a-de6b5ad2f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e212c84-eff3-4d3e-9aa2-879049ca3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450af6b-1656-41ee-a06f-52ccb55400b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        real_imgs = imgs.to(device)\n",
    "        batch_size_curr = real_imgs.size(0)\n",
    "\n",
    "        valid = torch.ones((batch_size_curr, 1), device=device)\n",
    "        fake = torch.zeros((batch_size_curr, 1), device=device)\n",
    "\n",
    "        # Train Generator \n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size_curr, latent_dim, device=device)\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train Discriminator \n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Show progress every 300 batches\n",
    "        if i % 300 == 0:\n",
    "            print(f\" Epoch [{epoch+1}/{epochs}], Batch [{i}/{len(dataloader)}] — \"\n",
    "                  f\"G Loss: {g_loss.item():.4f}, D Loss: {d_loss.item():.4f}\")\n",
    "\n",
    "    # Generate and save image after each epoch\n",
    "    z = torch.randn(25, latent_dim, device=device)\n",
    "    gen_imgs = generator(z).detach().cpu()\n",
    "    gen_imgs =(gen_imgs + 1)/2\n",
    "    grid = np.transpose(torchvision.utils.make_grid(gen_imgs, nrow=5, padding=2, normalize=False), (1, 2, 0))\n",
    "    plt.imshow(grid.numpy())\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"gan_images/epoch_{epoch+1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Just one statement after each epoch\n",
    "    print(f\" Epoch {epoch+1} complete — Check the image in 'gan_images/epoch_{epoch+1}.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb671c-a792-4823-bd47-3035469f9f3e",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "# After your training loop finishes\n",
    "torch.save(generator.state_dict(), \"generator.pth\")\n",
    "print(\" Generator model saved as generator.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4fa4da-b44e-4df2-bcc5-fd3bd2662995",
   "metadata": {
    "panel-layout": {
     "height": 701,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SAME settings from training \n",
    "latent_dim = 85\n",
    "image_size = \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generator definition (MUST match training)\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, 256),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Linear(1024, image_size * image_size),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, image_size, image_size)\n",
    "        return img\n",
    "\n",
    "# Load trained generator\n",
    "generator = Generator().to(device)\n",
    "generator.load_state_dict(torch.load(\"generator.pth\", map_location=device))\n",
    "generator.eval()\n",
    "\n",
    "# Generate new fake images\n",
    "z = torch.randn(25, latent_dim, device=device)\n",
    "gen_imgs = generator(z).detach().cpu()\n",
    "\n",
    "# Rescale from [-1, 1] to [0, 1]\n",
    "gen_imgs =(gen_imgs + 1)/2\n",
    "\n",
    "# Display in a grid \n",
    "grid = np.transpose(torchvision.utils.make_grid(gen_imgs, nrow=5, padding=2, normalize=False), (1, 2, 0))\n",
    "plt.imshow(grid.numpy(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac80bf0-9259-4db5-bfa3-84e4db9165e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Testing \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_image_by_number(generator, number, latent_dim, device):\n",
    "    generator.eval()\n",
    "    torch.manual_seed(number)  # same number → same random z\n",
    "    z = torch.randn(1, latent_dim, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img = generator(z).cpu()\n",
    "\n",
    "    # Scale [-1, 1] → [0, 1]\n",
    "    img = 0.5*(img + 1)\n",
    "    img = img.squeeze(0).permute(1, 2, 0).numpy()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Ask user for input\n",
    "num = int(input(\"Enter a number: \"))\n",
    "generate_image_by_number(generator, num, latent_dim, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959b6fb-ff7d-4954-a670-7936623a2477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "panel-cell-order": [
   "84f494b4-5398-4a02-9d75-5b5d0cc02eee",
   "7bcb671c-a792-4823-bd47-3035469f9f3e",
   "1a4fa4da-b44e-4df2-bcc5-fd3bd2662995"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
